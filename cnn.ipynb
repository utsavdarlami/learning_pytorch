{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helllo torch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "# torch.__version__\n",
    "\n",
    "\n",
    "print(\"Helllo torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{available_device} is available\")\n",
    "device = torch.device(device=available_device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN in pytorch\n",
    "\n",
    "- Stanfords notes Convolutional neural network\n",
    "     - https://cs231n.github.io/convolutional-networks/\n",
    "  \n",
    "  \n",
    "- Conv2d document from pytorch\n",
    "    - https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n",
    "    - In the simplest case, the output value of the conv layer with input size $(N, C_{\\text{in}}, H, W)$ has an output size $(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})$ \n",
    "    - N is a batch size, C denotes a number of channels, H is a height of input planes in pixels, and W is width in pixels.\n",
    "    \n",
    "    \n",
    "- Pooling document from pytorch\n",
    "    - https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layer Pytorch Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Input: (N, C_{in}, H_{in}, W_{in}) $$\n",
    "\n",
    "$$ Output: (N, C_{out}, H_{out}, W_{out}) $$\n",
    "\n",
    "$$where,$$\n",
    "\n",
    "$$H_{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0] \\times (\\text{kernel_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor$$\n",
    "\n",
    "$$W_{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1] \\times (\\text{kernel_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 6, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With square kernels and equal stride\n",
    "conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5 ) #,stride=2, padding=1)\n",
    "input = torch.randn(64, 3, 32, 32)\n",
    "c1_output = conv1(input)\n",
    "c1_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The parameters kernel_size, stride, padding, dilation can either be:\n",
    "- a single int – in which case the same value is used for the height and width dimension\n",
    "- a tuple of two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 10, 10])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With square kernels and equal stride\n",
    "c2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5,5))  # ,stride=(2,2),padding=1)\n",
    "\n",
    "# non-square kernels and unequal stride and with padding\n",
    "# m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "max_output = m_pool(c1_output)\n",
    "\n",
    "c2_output = c2(max_output)\n",
    "c2_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Max Pooling layer Pytorch Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 5, 5])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pool of square window of size=3, stride=2\n",
    "m_pool = nn.MaxPool2d(2, stride=2)\n",
    "# pool of non-square window\n",
    "# m = nn.MaxPool2d((3, 2), stride=(2, 1))\n",
    "\n",
    "# input = torch.randn(20, 16, 50, 32)\n",
    "# this output comes from the above conv layer\n",
    "max_output_2 = m_pool(c2_output)\n",
    "max_output_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 784])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_linear = max_output.reshape(max_output.shape[0], -1)\n",
    "max_linear.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Finally implementation on CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "train_set = datasets.CIFAR10(root=\"pytorch_dataset\",\n",
    "                           download=True,\n",
    "                           transform=transforms.ToTensor()\n",
    "                          )\n",
    "test_set = datasets.CIFAR10(root=\"pytorch_dataset\",\n",
    "                           train=False,\n",
    "                           download=True,\n",
    "                           transform=transforms.ToTensor()\n",
    "                          )\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(dataset=test_set, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "tensor(0.0019)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print(x.shape)\n",
    "    print((x/255).mean())\n",
    "    break\n",
    "    \n",
    "# 32*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*5*5,128)\n",
    "        self.fc2 = nn.Linear(128,num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.reshape(x.shape[0], -1) # flatten CONV -> FC\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 3\n",
    "num_classes = 10\n",
    "num_epochs = 3\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn model initialized using the CNN class defined earlier\n",
    "cnn_model = CNN(n_channels, num_classes).to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import Adam\n",
    "from torch import optim\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss at the end of 0 epoch is 1.8232377767562866\n",
      " loss at the end of 1 epoch is 1.0600694417953491\n",
      " loss at the end of 2 epoch is 1.1026233434677124\n",
      "Done Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for x_train, y_train in train_loader:\n",
    "        x_train = x_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "#         x_train = x_train/255\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = cnn_model(x_train)\n",
    "        \n",
    "        loss = criterion(y_pred, y_train)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\" loss at the end of {epoch} epoch is {loss}\")\n",
    "\n",
    "print(\"Done Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test_loader, model,cuda=True):\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in test_loader:\n",
    "            if cuda:\n",
    "                x_test = x_test.to(device)\n",
    "                y_test = y_test.to(device=device)\n",
    "            x_test = x_test.float()/255\n",
    "            preds = model(x_test)\n",
    "            _, preds_idx = preds.max(1)\n",
    "            n_correct += (preds_idx==y_test).sum().item()\n",
    "            n_total += x_test.size(0)\n",
    "    print(f\"Out of {n_total} images {n_correct} where correctly classified\")\n",
    "    acc = (n_correct/n_total) * 100\n",
    "    print(f\"Accuracy of the model is {acc:.2f}\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 10000 images 5333 where correctly classified\n",
      "Accuracy of the model is 53.33\n"
     ]
    }
   ],
   "source": [
    "accuracy(test_loader, cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'state_dict' : cnn_model.state_dict(), 'optimizer' : optimizer.state_dict()}\n",
    "# save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth.tar'\n",
    "torch.save(checkpoint, PATH)\n",
    "print(\"check point saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN()\n",
    "l_optimizer = Adam(net.parameters(), lr=lr)\n",
    "checkpoint_loaded = torch.load(PATH)\n",
    "\n",
    "net.load_state_dict(checkpoint['state_dict'])\n",
    "l_optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 10000 images 5333 where correctly classified\n",
      "Accuracy of the model is 53.33\n"
     ]
    }
   ],
   "source": [
    "accuracy(test_loader, net,cuda=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Create a predicting functions\n",
    "- [ ] Print loss after certain batch size\n",
    "- [ ] Look into the data with high loss in training as shown in fastai course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN on Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "from skimage import io\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9', '5', '3', '4', '1', '7', 'pa', '8', '6', '2', '0', 'BA']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = \"../NLPR/myLPR/finalFolder/\"\n",
    "folders = os.listdir(folder_path)\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16980"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# license_csv = pd.read_csv(\"finalPathAndImage.csv\",low_memory=False)\n",
    "# len(license_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17315\n"
     ]
    }
   ],
   "source": [
    "# digit_image_label  = pd.DataFrame()\n",
    "# all_images = []\n",
    "# all_labels = []\n",
    "# for digit_folder in folders:\n",
    "#     digit_path = folder_path + digit_folder\n",
    "# #     print(digit_path)\n",
    "#     images = os.listdir(digit_path)\n",
    "# #     print(images[:5])\n",
    "# #     print(final['label'][:5])\n",
    "#     all_images.extend(images)\n",
    "#     all_labels.extend(len(images)*[digit_folder])\n",
    "\n",
    "# print(len(all_images))\n",
    "# #     break\n",
    "# digit_image_label['image_path'] = pd.Series(all_images)\n",
    "# digit_image_label['label'] = pd.Series(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17315"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(digit_image_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digit_image_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digit_image_label.to_csv(\"digit_and_label.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_label = \"digit_and_label.csv\"\n",
    "root_dir = \"../NLPR/myLPR/finalFolder/\"\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NepaliDigitDataset(Dataset):\n",
    "    def __init__(self,csv_file, root_dir, transform=None):\n",
    "        self.root = root_dir\n",
    "        self.transform = transform\n",
    "        self.digit_frame =  pd.read_csv(csv_file, low_memory=False)\n",
    "    def __len__(self):\n",
    "        return len(self.digit_frame)\n",
    "    def __getitem__(self, index):\n",
    "        digit = self.digit_frame.iloc[index, 1]\n",
    "        img_name = self.digit_frame.iloc[index, 0]\n",
    "        img_path = os.path.join(self.root + digit + \"/\" + img_name)\n",
    "        image = io.imread(img_path)\n",
    "        image = resize(image,(32, 32,3))\n",
    "        if digit==\"pa\":\n",
    "            digit=10\n",
    "        if digit==\"BA\":\n",
    "            digit=11\n",
    "        y_label = torch.tensor(int(digit))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return (image, y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "])\n",
    "dataset = NepaliDigitDataset(digit_label,root_dir,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(dataset,[2315,15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "tensor([ 2,  0, 11,  4,  1,  2,  1,  9, 11,  6,  3,  9,  3,  0,  3,  8,  6,  6,\n",
      "         0,  0,  9,  0, 11,  5, 11, 11,  8,  0, 10,  5,  1,  8,  6, 10,  6,  3,\n",
      "         6,  0,  4,  8,  0, 10,  5,  0,  2, 11,  2,  7,  2,  9,  6,  1, 11,  6,\n",
      "         5,  3,  0, 11,  6,  0,  9, 11,  7,  3])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*5*5,128)\n",
    "        self.fc2 = nn.Linear(128,num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.reshape(x.shape[0], -1) # flatten CONV -> FC\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 3\n",
    "num_classes = 12\n",
    "num_epochs = 20\n",
    "lr = 0.001\n",
    "\n",
    "# n_channels = 3\n",
    "# num_classes = 10\n",
    "# num_epochs = 3\n",
    "# lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn model initialized using the CNN class defined earlier\n",
    "cnn_model = CNN(n_channels, num_classes).to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True) # factor=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss at the end of 0 epoch is 2.3432869911193848\n",
      " loss at the end of 1 epoch is 2.623555898666382\n",
      " loss at the end of 2 epoch is 2.3396313190460205\n",
      " loss at the end of 3 epoch is 2.568519353866577\n",
      " loss at the end of 4 epoch is 2.4552524089813232\n",
      " loss at the end of 5 epoch is 2.457399845123291\n",
      " loss at the end of 6 epoch is 2.6387178897857666\n",
      " loss at the end of 7 epoch is 2.519538164138794\n",
      " loss at the end of 8 epoch is 2.285705327987671\n",
      " loss at the end of 9 epoch is 2.296299457550049\n",
      " loss at the end of 10 epoch is 2.18076753616333\n",
      " loss at the end of 11 epoch is 2.6413867473602295\n",
      " loss at the end of 12 epoch is 2.3331358432769775\n",
      " loss at the end of 13 epoch is 2.306072235107422\n",
      " loss at the end of 14 epoch is 2.535757303237915\n",
      " loss at the end of 15 epoch is 2.498894453048706\n",
      " loss at the end of 16 epoch is 2.5984904766082764\n",
      " loss at the end of 17 epoch is 2.4779984951019287\n",
      " loss at the end of 18 epoch is 2.0723512172698975\n",
      " loss at the end of 19 epoch is 2.549471616744995\n",
      "Done Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    for x_train, y_train in train_loader:\n",
    "        x_train = x_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        x_train = x_train.float()/255\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = cnn_model(x_train)\n",
    "        \n",
    "        loss = criterion(y_pred, y_train)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    mean_loss = sum(losses)/ len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "    \n",
    "    print(f\" loss at the end of {epoch} epoch is {loss}\")\n",
    "\n",
    "print(\"Done Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 6000 images 1308 where correctly classified\n",
      "Accuracy of the model is 21.80\n"
     ]
    }
   ],
   "source": [
    "accuracy(test_loader, cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "name": "Untitled1.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
