{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f39c5072",
   "metadata": {},
   "source": [
    "#  Graph attention networks (GAT) implementation\n",
    "- https://www.youtube.com/watch?v=A-yKQamf2Fc [Understanding Graph Attention Networks]\n",
    "- https://www.youtube.com/watch?v=CwsPoa7z2c8 [Pytorch Geometric tutorial: Graph attention networks (GAT) implementation]\n",
    "- https://github.com/AntonioLonga/PytorchGeometricTutorial/blob/main/Tutorial3/Tutorial3.ipynb\n",
    "- https://github.com/rish-16/pytorch-graphdl/blob/main/gat/layers.py\n",
    "- https://github.com/rish-16/gin-attn-conv-pytorch/blob/main/gin_attn_pytorch/gin_attn_conv.py\n",
    "- https://arxiv.org/abs/1710.10903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cc10487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as tnn \n",
    "from torch_geometric import nn as gnn\n",
    "from torch_geometric.utils import add_self_loops, degree, softmax\n",
    "from torch_scatter import scatter\n",
    "from torch_geometric.data import Data\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9377f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75540b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 1],\n",
    "                           [1, 0],\n",
    "                           [1, 2],\n",
    "                           [2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3661f27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges = edge_index.numpy()\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "nx.draw_networkx(G, with_labels=False, node_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c3dfa9",
   "metadata": {},
   "source": [
    "## Dummy GAT Layer\n",
    "- Was possible due to following resources\n",
    "    - https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/gat_conv.html#GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ffd60233",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyGATLayer(gnn.MessagePassing):\n",
    "    def __init__(self, in_channels=2, out_channels=4):\n",
    "        super().__init__(aggr='add')\n",
    "        \n",
    "        self.linear1 = tnn.Linear(in_features=in_channels, out_features=out_channels)\n",
    "        self.attn_linear = tnn.Linear(in_features=2*out_channels, out_features=1)\n",
    "        \n",
    "        self.leaky_relu = tnn.LeakyReLU(negative_slope=0.2)\n",
    "        \n",
    "    def forward(self, x , edge_index, edge_attrs=None):\n",
    "        \n",
    "        edge_index, _  = add_self_loops(edge_index, num_nodes=x.shape[0])\n",
    "        h = self.linear1(x)\n",
    "        logger.info(f\"|after linear layer {h.shape}|\") \n",
    "\n",
    "        out = self.propagate(edge_index, x=x, h=h)\n",
    "        # the propagate calls \n",
    "           # - message\n",
    "           # - aggregate\n",
    "           # - update\n",
    "        return out\n",
    "    \n",
    "    def message(self, h_i, h_j, edge_index, index):\n",
    "        \n",
    "#         src_node_idx, dst_node_idx = edge_index\n",
    "#         logger.info(src_node_idx)\n",
    "#         logger.info(dst_node_idx)\n",
    "\n",
    "#         logger.info(x_i.shape)\n",
    "#         logger.info(x_j.shape)\n",
    "        logger.info(\"*\"*50)\n",
    "        logger.info(h_i.shape)\n",
    "        logger.info(h_j.shape)\n",
    "        \n",
    "        # Here we Concat the src node embeds and dst node embeds/features\n",
    "        cat = torch.cat([h_i, h_j], dim=1) # [7, 4]\n",
    "        \n",
    "        logger.info(\"Concat\" + \"*\"*50)\n",
    "        logger.info(cat.shape)\n",
    "#         logger.info(cat)\n",
    "        \n",
    "#         now need to pass this concat feature to the feed-forward layer to get attention score\n",
    "        e_j = self.attn_linear(cat)   # [7, 1]\n",
    "        logger.info(\"e_J\" + \"*\"*50)\n",
    "        logger.info(e_j)\n",
    "        logger.info(e_j.shape) \n",
    "        \n",
    "        logger.info(f\"Node index passed {index}\") # dst node idx\n",
    "        alphas = softmax(self.leaky_relu(e_j), index=index) # performs softmax with the neighbouring nodes.\n",
    "        logger.info(alphas.shape)\n",
    "        logger.info(f\"Attention coefficient are : {alphas}\")\n",
    "        # lets check if the sum is 1 or not for each nodes\n",
    "        sum_of_node_attn_score = scatter(alphas, index, dim=0, reduce='sum')\n",
    "        logger.info(f\"Sum are : {sum_of_node_attn_score}\")\n",
    "        logger.info(\"*\"*50)\n",
    "       \n",
    "            \n",
    "        msg = alphas * h_j\n",
    "        logger.info(msg.shape)\n",
    "        logger.info(msg)\n",
    "        logger.info(\"*\"*50)\n",
    "\n",
    "        return msg\n",
    "        \n",
    "    def update(self, aggr_out, x):\n",
    "        logger.info(x)\n",
    "        logger.info(aggr_out)\n",
    "        return aggr_out\n",
    "\n",
    "# class DummyGATLayer(gnn.MessagePassing):\n",
    "#     def __init__(self, in_channels=1, out_channels=2):\n",
    "#         super().__init__(aggr='add')\n",
    "        \n",
    "#         self.linear1 = tnn.Linear(in_features=in_channels, out_features=out_channels)\n",
    "#         self.attn_linear = tnn.Linear(in_features=2*out_channels, out_features=1)\n",
    "        \n",
    "#         self.leaky_relu = tnn.LeakyReLU(negative_slope=0.2)\n",
    "        \n",
    "#     def forward(self, x , edge_index, edge_attrs=None):\n",
    "        \n",
    "#         edge_index, _  = add_self_loops(edge_index, num_nodes=x.shape[0])\n",
    "#         h = self.linear1(x)\n",
    "#         out = self.propagate(edge_index, x=x, h=h)\n",
    "#         return out\n",
    "    \n",
    "#     def message(self, h_i, h_j, edge_index, index):\n",
    "                \n",
    "#         # Here we Concat the src node embeds and dst node embeds/features\n",
    "#         cat = torch.cat([h_i, h_j], dim=1) # [num_nodes, 2 * out_channels]\n",
    "               \n",
    "#         # now need to pass this concat feature to the feed-forward layer to get attention score\n",
    "#         e_j = self.attn_linear(cat) # [num_nodes, 1]\n",
    "#         alphas = softmax(self.leaky_relu(e_j), index=index) # performs softmax with the neighboring nodes.       \n",
    "            \n",
    "#         msg = alphas * h_j\n",
    "\n",
    "#         return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a49c7d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "dummy_gat = DummyGATLayer(in_channels=1, out_channels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4257e3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 01:19:37.609 | INFO     | __main__:forward:14 - |after linear layer torch.Size([3, 2])|\n",
      "2022-03-08 01:19:37.611 | INFO     | __main__:message:31 - **************************************************\n",
      "2022-03-08 01:19:37.611 | INFO     | __main__:message:32 - torch.Size([7, 2])\n",
      "2022-03-08 01:19:37.612 | INFO     | __main__:message:33 - torch.Size([7, 2])\n",
      "2022-03-08 01:19:37.612 | INFO     | __main__:message:38 - Concat**************************************************\n",
      "2022-03-08 01:19:37.613 | INFO     | __main__:message:39 - torch.Size([7, 4])\n",
      "2022-03-08 01:19:37.614 | INFO     | __main__:message:44 - e_J**************************************************\n",
      "2022-03-08 01:19:37.614 | INFO     | __main__:message:45 - tensor([[0.8283],\n",
      "        [0.8859],\n",
      "        [0.8859],\n",
      "        [0.9435],\n",
      "        [0.8283],\n",
      "        [0.8859],\n",
      "        [0.9435]], grad_fn=<AddmmBackward>)\n",
      "2022-03-08 01:19:37.616 | INFO     | __main__:message:46 - torch.Size([7, 1])\n",
      "2022-03-08 01:19:37.618 | INFO     | __main__:message:48 - Node index passed tensor([1, 0, 2, 1, 0, 1, 2])\n",
      "2022-03-08 01:19:37.619 | INFO     | __main__:message:50 - torch.Size([7, 1])\n",
      "2022-03-08 01:19:37.622 | INFO     | __main__:message:51 - Attention coefficient are : tensor([[0.3143],\n",
      "        [0.5144],\n",
      "        [0.4856],\n",
      "        [0.3527],\n",
      "        [0.4856],\n",
      "        [0.3330],\n",
      "        [0.5144]], grad_fn=<DifferentiableGraphBackward>)\n",
      "2022-03-08 01:19:37.628 | INFO     | __main__:message:54 - Sum are : tensor([[1.],\n",
      "        [1.],\n",
      "        [1.]], grad_fn=<ScatterAddBackward>)\n",
      "2022-03-08 01:19:37.629 | INFO     | __main__:message:55 - **************************************************\n",
      "2022-03-08 01:19:37.631 | INFO     | __main__:message:59 - torch.Size([7, 2])\n",
      "2022-03-08 01:19:37.633 | INFO     | __main__:message:60 - tensor([[-0.3139,  0.0279],\n",
      "        [-0.1205,  0.4725],\n",
      "        [-0.1138,  0.4461],\n",
      "        [ 0.1870,  0.6168],\n",
      "        [-0.4850,  0.0430],\n",
      "        [-0.0780,  0.3059],\n",
      "        [ 0.2728,  0.8995]], grad_fn=<MulBackward0>)\n",
      "2022-03-08 01:19:37.636 | INFO     | __main__:message:61 - **************************************************\n",
      "2022-03-08 01:19:37.639 | INFO     | __main__:update:66 - tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "2022-03-08 01:19:37.641 | INFO     | __main__:update:67 - tensor([[-0.6055,  0.5156],\n",
      "        [-0.2049,  0.9505],\n",
      "        [ 0.1590,  1.3456]], grad_fn=<ScatterAddBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6055,  0.5156],\n",
       "        [-0.2049,  0.9505],\n",
       "        [ 0.1590,  1.3456]], grad_fn=<ScatterAddBackward>)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_gat(data.x, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ea650fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1206, -0.1111],\n",
      "        [-0.0583,  0.0537],\n",
      "        [-0.1619,  0.1491]], grad_fn=<AsStridedBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.3252, 0.0464],\n",
       "        [0.9134, 0.1730],\n",
       "        [1.2485, 0.2452]], grad_fn=<ScatterAddBackward>)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "gat_pyg = gnn.GATConv(1, 2)\n",
    "\n",
    "print(gat_pyg(data.x, data.edge_index))\n",
    "\n",
    "dummy_gat = DummyGATLayer(in_channels=1, out_channels=2)\n",
    "dummy_gat(data.x, data.edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
