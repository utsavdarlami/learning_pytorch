{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fifteen-playing",
   "metadata": {},
   "source": [
    "# Generating the name using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-stranger",
   "metadata": {},
   "source": [
    "### Resources\n",
    "#### Video\n",
    "- https://www.youtube.com/watch?v=WujVlF_6h5A\n",
    "\n",
    "#### Code\n",
    "- https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Projects/text_generation_babynames/generating_names.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minor-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "# from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "southeast-stranger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "print(a_device)\n",
    "device = torch.device(a_device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hollow-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import string\n",
    "import random\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "working-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "changed-oliver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "center-wayne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lesser-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_files = unidecode.unidecode(open(\"./data/names.txt\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "romance-bibliography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "architectural-andrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28529.015625"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names_files)/256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-wireless",
   "metadata": {},
   "source": [
    "## Let's breakdown the video \n",
    "- creates the rnn model, but the shape does not match to my previous cases\n",
    "- creates a generator class for \n",
    "     - get a batch of data\n",
    "     - train the rnn model\n",
    "     - generate name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "dated-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "   \n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "#         self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        \n",
    "#         self.h, self.c = self.__init_h0_c0__()\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        # out to tag\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self,x, hidden, cell):\n",
    "        emb_x = self.embedding_layer(x)\n",
    "#         print(emb_x.shape)\n",
    "        out, (hidden, cell) = self.lstm(emb_x, (hidden, cell))\n",
    "        hidden = hidden.detach()\n",
    "        cell = cell.detach()\n",
    "        \n",
    "        out = self.linear(out.view(-1, self.hidden_size))\n",
    "        \n",
    "        return out, (hidden, cell)        \n",
    "    \n",
    "    def init_h0_c0(self, batch_size):\n",
    "        return (\n",
    "            torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device),\n",
    "            torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-contract",
   "metadata": {},
   "source": [
    "## Creating the generator class for training and generaing word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "specialized-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    def __init__(self):\n",
    "        self.chunk_len = 250\n",
    "        self.embedding = 256\n",
    "        self.num_epochs = 2000\n",
    "        self.batch_size = 1\n",
    "        self.hidden_size = 256\n",
    "        self.num_layers = 2\n",
    "        self.lr = 0.001\n",
    "       \n",
    "    def prepare_sequence(self, string):\n",
    "        \"\"\"\n",
    "            Takes a string a \n",
    "            Returns a tensor containing the index of the letters in the string.\n",
    "        \"\"\"\n",
    "        index_ = [all_characters.index(s) for s in string]\n",
    "        return torch.tensor(index_)\n",
    "    \n",
    "    def get_batch(self):\n",
    "        \"\"\" \n",
    "            returns a random 256 chunk of letter\n",
    "        \"\"\"\n",
    "        start_idx = random.randint(0, len(names_files) - self.chunk_len)\n",
    "        end_idx = start_idx + self.chunk_len + 1\n",
    "        text_str = names_files[start_idx:end_idx]\n",
    "        text_input = torch.zeros(self.batch_size, self.chunk_len)\n",
    "        text_target = torch.zeros(self.batch_size, self.chunk_len)\n",
    "\n",
    "        for i in range(1):\n",
    "            text_input[i, :] = self.prepare_sequence(text_str[:-1])\n",
    "            text_target[i, :] = self.prepare_sequence(text_str[1:])\n",
    "           \n",
    "        return text_input.long(), text_target.long()\n",
    "#         pass\n",
    "#         return inputs, targets\n",
    "    \n",
    "    def generate_names(self, initial_str=\"A\", temperature=0.85, prediction_len=100):\n",
    "        hidden, cell = self.model.init_h0_c0(self.batch_size)\n",
    "        initial_str_tensor = self.prepare_sequence(initial_str)\n",
    "        \n",
    "        # for new hidden and cell based on input only if length is > 1\n",
    "        for l in range(len(initial_str)-1):\n",
    "            _, hidden, cell = self.model(initial_str_tensor.view(1,1).to(device), \n",
    "                                         (hidden, cell))\n",
    "        \n",
    "        \"\"\"\n",
    "            now generating letters per letter\n",
    "        \"\"\"\n",
    "        \n",
    "        predicted = initial_str # result should start from initial_str\n",
    "        # selecting the last character index\n",
    "        last_char_idx = initial_str_tensor[-1]\n",
    "        \n",
    "        for p in range(prediction_len):\n",
    "            output, (hidden, cell) = self.model(\n",
    "                last_char_idx.view(1,1).to(device), hidden, cell\n",
    "            ) \n",
    "            output_dist = output.data.view(-1).div(0.85).exp()\n",
    "            top_char = torch.multinomial(output_dist, num_samples=1)[0]\n",
    "            predicted_char = all_characters[top_char]\n",
    "            predicted += predicted_char\n",
    "            last_char_idx = self.prepare_sequence(predicted_char)\n",
    "\n",
    "        return predicted\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "            \n",
    "        \"\"\"\n",
    "        self.model = RNN(n_characters, \n",
    "                    self.embedding, \n",
    "                    self.hidden_size,\n",
    "                    self.num_layers,\n",
    "                    n_characters\n",
    "                   ).to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        for epoch in range(1,self.num_epochs + 1):\n",
    "            inputs, targets = self.get_batch()\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            hidden, cell = self.model.init_h0_c0(self.batch_size)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs, (hidden, cell) = self.model(inputs, hidden, cell)\n",
    "#             print(outputs.shape)\n",
    "            \n",
    "            loss = criterion(outputs, targets.squeeze())\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            if epoch%500==0:\n",
    "                print(f\"epochs {epoch}, loss {loss.item()}\")\n",
    "                print(self.generate_names())\n",
    "#                 py_max, idx = outputs.cpu().detach().max(1)\n",
    "#                 out_w = [all_characters[y.item()] for y in idx.squeeze()]\n",
    "#                 print(f\"Direct : {''.join(out_w[:5])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "front-tragedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 500, loss 2.2552311420440674\n",
      "AZwell\n",
      "Cister\n",
      "Clayna\n",
      "Jegar\n",
      "Lentelly\n",
      "Shadna\n",
      "Lone\n",
      "Teag\n",
      "Caabie\n",
      "Samhameo\n",
      "Cadie\n",
      "Sosmina\n",
      "Jana\n",
      "Alaniele\n",
      "Than\n",
      "epochs 1000, loss 1.7891860008239746\n",
      "Aburtie\n",
      "Sapher\n",
      "Dulty\n",
      "Auliana\n",
      "Deanar\n",
      "Jamia\n",
      "Vevan\n",
      "Hathrir\n",
      "Demanie\n",
      "Micabe\n",
      "Jeferi\n",
      "Orian\n",
      "Daverian\n",
      "Jafrey\n",
      "M\n",
      "epochs 1500, loss 1.9733999967575073\n",
      "Alvayah\n",
      "Joannie\n",
      "Sana\n",
      "Gi\n",
      "Kristi\n",
      "Antonia\n",
      "Aury\n",
      "Linjandon\n",
      "Bristine\n",
      "Flay\n",
      "Austallin\n",
      "Irenee\n",
      "Albor\n",
      "Nataliol\n",
      "E\n",
      "epochs 2000, loss 1.3745120763778687\n",
      "ACler\n",
      "Branden\n",
      "Mari\n",
      "Joan\n",
      "Janelle\n",
      "Jenida\n",
      "Debse\n",
      "Jene\n",
      "Robby\n",
      "Isha\n",
      "Brookanne\n",
      "Leiliah\n",
      "Maryan\n",
      "Glendo\n",
      "Jasem\n",
      "Mi\n"
     ]
    }
   ],
   "source": [
    "name_generator = Generator()\n",
    "name_generator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "consolidated-oregon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Udrine\n",
      "Belis\n",
      "Gabry\n",
      "Baylen\n",
      "Julie\n",
      "Diana\n",
      "Avia\n",
      "Marisa\n",
      "Migguel\n",
      "Harrie\n",
      "Trencence\n",
      "Ashlis\n",
      "Alis\n",
      "Grossie\n",
      "Charl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(name_generator.generate_names(initial_str=\"U\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-plant",
   "metadata": {},
   "source": [
    "### Breaking the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eastern-august",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([48, 10, 27, 34])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(names_files[:4])\n",
    "prepare_sequence(names_files[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "worst-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_random_batch(self):\n",
    "start_idx = random.randint(0, len(names_files) - 250)\n",
    "end_idx = start_idx + 250 + 1\n",
    "text_str = names_files[start_idx:end_idx]\n",
    "text_input = torch.zeros(1, 250)\n",
    "text_target = torch.zeros(1, 250)\n",
    "\n",
    "for i in range(1):\n",
    "    text_input[i, :] = name_generator.prepare_sequence(text_str[:-1])\n",
    "    text_target[i, :] = name_generator.prepare_sequence(text_str[1:])\n",
    "\n",
    "# return text_input.long(), text_target.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "decent-thomas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 250])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "russian-korean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([96.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_target[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "attached-reception",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([250, 100])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_x = torch.rand(250, 100)\n",
    "emb_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hindu-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dist = emb_x.data.view(-1).div(0.85).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "possible-somewhere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "noted-tomorrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 256])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0, c0 = name_generator.model.init_h0_c0(1)\n",
    "h0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "nasty-doctor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_str= \"A\"\n",
    "initial_input = name_generator.prepare_sequence(initial_str)\n",
    "initial_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "stock-textbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ha'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = initial_str\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "proof-fields",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_input.view(1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "honest-ballet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop\n"
     ]
    }
   ],
   "source": [
    "for p in range(len(initial_str) - 1):\n",
    "    _, (hidden, cell) = name_generator.model(\n",
    "        initial_input[p].view(1).unsqueeze(0).to(device), hidden, cell\n",
    "    )\n",
    "    print(\"loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "undefined-assignment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_char = initial_input[-1]\n",
    "last_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "destroyed-nelson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_char.view(1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "public-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(10):\n",
    "    output, (h0, c0) = name_generator.model(\n",
    "        last_char.view(1,1).to(device), h0, c0\n",
    "    ) \n",
    "    output_dist = output.data.view(-1).div(0.85).exp()\n",
    "    top_char = torch.multinomial(output_dist, num_samples=1)[0]\n",
    "    predicted_char = all_characters[top_char]\n",
    "    predicted += predicted_char\n",
    "    last_char = name_generator.prepare_sequence(predicted_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "american-hybrid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ha\\nRanner\\nKuke\\nEler\\nYeudon\\nErgel'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-waterproof",
   "metadata": {},
   "source": [
    "### Experimenting my generation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "conditional-recycling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 256])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden, cell = name_generator.model.init_h0_c0(1)\n",
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "wireless-chile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([43, 10])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_str= \"Ha\"\n",
    "initial_input = name_generator.prepare_sequence(initial_str)\n",
    "initial_input\n",
    "# initial_input.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "confirmed-tennis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[43]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_char_idx = initial_input[-1]\n",
    "last_char_idx.view(1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "statutory-detective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(43)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_char_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "local-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, (hidden, cell) = name_generator.model(initial_input.view(1,2).to(device), hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "rocky-graduation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "graphic-specific",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 256])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "upper-departure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dist = output.data.view(-1).div(0.85).exp()\n",
    "output_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "english-consciousness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14], device='cuda:0')"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(output_dist, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "partial-recruitment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_n = initial_str\n",
    "predicted_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "gothic-aggregate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[23]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.view(1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "eleven-beverage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Ja\n"
     ]
    }
   ],
   "source": [
    "print(predicted_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "soviet-occurrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "From 43 --> H\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n",
      "\n",
      "From 10 --> a\n",
      "To ; 27 --> r\n",
      "\n",
      "From 27 --> r\n",
      "To ; 21 --> l\n",
      "\n",
      "From 21 --> l\n",
      "To ; 14 --> e\n",
      "\n",
      "From 14 --> e\n",
      "To ; 96 --> \n",
      "\n",
      "\n",
      "From 96 --> \n",
      "\n",
      "To ; 45 --> J\n",
      "\n",
      "From 45 --> J\n",
      "To ; 10 --> a\n"
     ]
    }
   ],
   "source": [
    "initial_str= \"H\"\n",
    "initial_input = name_generator.prepare_sequence(initial_str)\n",
    "# initial_input\n",
    "# initial_input.unsqueeze(0).shape\n",
    "\n",
    "last_char_idx = initial_input[-1]\n",
    "# last_char_idx.view(1).unsqueeze(0)\n",
    "predicted_n = initial_str\n",
    "\n",
    "for i in range(100):\n",
    "    print()\n",
    "    print(f\"From {last_char_idx.item()} --> {all_characters[last_char_idx.item()]}\")\n",
    "    outputs, (hidden, cell) = name_generator.model(last_char_idx.view(1).unsqueeze(0).to(device), hidden, cell)\n",
    "    \n",
    "    outputs = nn.functional.softmax(outputs, 1)\n",
    "    py_max, last_char_idx = outputs.cpu().detach().max(1)\n",
    "    \n",
    "    print(f\"To ; {last_char_idx.item()} --> {all_characters[last_char_idx.item()]}\")\n",
    "    \n",
    "    last_char = all_characters[last_char_idx.item()]\n",
    "    predicted_n += last_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "senior-treatment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct : Harle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n",
      "Jarle\n"
     ]
    }
   ],
   "source": [
    "print(f\"Direct : {predicted_n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
