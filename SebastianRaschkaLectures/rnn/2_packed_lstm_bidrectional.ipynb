{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext.legacy import data\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "torchtext.__version__\n",
    "# torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_dataset in module get_dataset:\n",
      "\n",
      "get_dataset(include_lengths=False)\n",
      "    returns the\n",
      "    TEXT, LABEL, train_set, val_set and test_set\n",
      "    include_lengths=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from get_dataset import get_dataset\n",
    "help(get_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42  # The answer to life, the universe, and everything\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "available_device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "available_device= \"cpu\"\n",
    "device = torch.device(available_device)\n",
    "print(device)\n",
    "# device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataset and iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "TEXT, LABEL, train_set, val_set, test_set = get_dataset(include_lengths=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_set,\n",
    "                max_size=MAX_VOCAB_SIZE,\n",
    "                vectors=\"glove.6B.100d\",\n",
    "                unk_init = torch.Tensor.normal_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 464964),\n",
       " (',', 441024),\n",
       " ('.', 378556),\n",
       " ('a', 250866),\n",
       " ('and', 250751),\n",
       " ('of', 231374),\n",
       " ('to', 214406),\n",
       " ('is', 173465),\n",
       " ('in', 141132),\n",
       " ('I', 125873)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 10 common word train_set\n",
    "top_commom_words = TEXT.vocab.freqs.most_common(10)\n",
    "top_commom_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.1233,  0.3499,  0.6173],\n",
       "        [ 0.7262,  0.0912, -0.3891,  ...,  0.0821,  0.4440, -0.7240],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.3509, -0.8664,  1.1617,  ..., -0.5238, -1.9368,  0.2217],\n",
       "        [ 0.6168, -1.0092, -0.0051,  ..., -0.0352, -0.2554,  0.0779],\n",
       "        [ 0.4369,  0.3981, -0.2551,  ..., -0.3327,  0.4569,  0.6567]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25002, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 20235, '0': 20265})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'0': 0, '1': 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# https://torchtext.readthedocs.io/en/latest/data.html#bucketiterator\n",
    "train_iterator, val_iterator, test_iterator = data.BucketIterator.splits(\n",
    "                                              (train_set, val_set, test_set),\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              sort_within_batch=True,          #\n",
    "                                              sort_key=lambda x: len(x.REVIEWS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633\n",
      "torch.Size([223, 64])\n",
      "torch.Size([64])\n",
      "torch.Size([52, 64])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_iterator))\n",
    "for t_i in train_iterator:\n",
    "    print(t_i.REVIEWS[0].size())\n",
    "    print(t_i.LABEL.size())\n",
    "    break\n",
    "\n",
    "for v_i in val_iterator:\n",
    "    print(v_i.REVIEWS[0].size())\n",
    "    print(v_i.LABEL.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learnig about embedding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_l = nn.Embedding(32, 10, padding_idx=0)\n",
    "emb_l.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_text_dummy =  [[2,0,1,0,30], [1, 0, 29, 0 , 0]]  # extra 0's for padding\n",
    "input_ =  torch.LongTensor(batch_text_dummy).T\n",
    "input_.shape  # seq_len, batch_Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_ = emb_l(input_)\n",
    "out_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8888,  1.3465, -1.2052,  0.5617,  0.5860, -0.1069,  0.7700,  0.8317,\n",
       "         -0.8908, -0.0312],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.4977,  0.6553,  0.9393,  0.7443,  1.3530,  1.3392, -0.0201, -0.0159,\n",
       "         -0.6893, -1.1100],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [-1.0366, -2.0125,  0.2895, -0.1463, -1.6394,  0.0331, -1.6140,  0.6373,\n",
       "          1.8592, -1.4831]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3623, -0.4913,  1.1900, -1.3396,  0.2789,  0.0026,  0.6211, -1.4329,\n",
       "         -0.9110, -0.8595],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [-0.3568, -0.1084, -0.7495, -0.4504,  1.3501, -0.9847, -1.2822, -1.1335,\n",
       "          0.5987,  1.7185],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jut_[1]\n",
    "out_[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn  = nn.RNN(10, 3)\n",
    "rnn.all_weights[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.all_weights[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.all_weights[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.all_weights[0][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rnn, hid = rnn(out_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 3])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment_Analyzer2(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, \n",
    "                 out_dim, n_layers, bidirectional, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, \n",
    "                          hidden_size=hidden_dim,\n",
    "                          num_layers=n_layers,\n",
    "                          bidirectional=bidirectional,\n",
    "                          dropout=dropout)\n",
    "        \"\"\"\n",
    "        As the final hidden state of our LSTM has both a forward and a backward component, \n",
    "        which will be concatenated together, the size of the input to the nn.Linear layer \n",
    "        is twice that of the hidden dimension size.\n",
    "        \"\"\"\n",
    "        self.fc = nn.Linear(2*hidden_dim, out_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, text, text_lengths):\n",
    "        # text =  [ sent_len, batch_size]\n",
    "        # text_lenghts = [batch_size]\n",
    "        embeds = self.dropout(self.embedding(text))\n",
    "        # embedded = [sent_len, batch_size, embed_dim]\n",
    "        \n",
    "        #pack the sequence\n",
    "        \"\"\"\n",
    "        Before we pass our embeddings to the RNN, we need to pack them, \n",
    "        which we do with nn.utils.rnn.pack_padded_sequence. \n",
    "        This will cause our RNN to only process the non-padded elements of our sequence. \n",
    "        \n",
    "        Note that the lengths argument of packed_padded_sequence must be a CPU tensor \n",
    "        so we explicitly make it one by using .to('cpu').\n",
    "       \n",
    "        https://androidkt.com/pads-and-pack-variable-length-sequences-in-pytorch/\n",
    "        \"\"\"\n",
    "        packed_embeds = nn.utils.rnn.pack_padded_sequence(embeds, text_lengths.to('cpu'))\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embeds)\n",
    "        \n",
    "        \"\"\"\n",
    "        # unpack the output , not required for this case but adding for later reference\n",
    "         Without packed padded sequences, hidden and cell are tensors from the last element in the sequence,\n",
    "         which will most probably be a pad token,\n",
    "         however when using packed padded sequences they are both from the last non-padded element in the sequence. \n",
    "         We then unpack the output sequence, with nn.utils.rnn.pad_packed_sequence, to transform it from a packed sequence to a tensor. The elements of output from padding tokens will be zero tensors (tensors where every element is zero). Usually, we only have to unpack output if we are going to use it later on in the model. \n",
    "         Although we aren't in this case, we still unpack the sequence just to show how it is done.\n",
    "        \"\"\"\n",
    "        output = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        # output = [sent_len, batch_size, hid_dim * num_direction]\n",
    "        \n",
    "        #hidden = [num layers * num directions, batch size, hid dim]        \n",
    "        #cell = [num layers * num directions, batch size, hid dim]        \n",
    "        \n",
    "        \"\"\"\n",
    "        Concat the \n",
    "        - final forward (hidden[-2,:,:]) hidden state # normal hidden for 1 direction lstm\n",
    "        - and backward (hidden[-1,:,:]) hidden state \n",
    "        then apply dropout \n",
    "        this is because we used bidirectional lstm\n",
    "        \"\"\"\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "            \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_IDX  =  TEXT.vocab.stoi[TEXT.pad_token]\n",
    "UNK_IDX  =  TEXT.vocab.stoi[TEXT.unk_token]\n",
    "print(PAD_IDX)\n",
    "print(UNK_IDX)\n",
    "TEXT.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size, embedding_dim, hidden_dim, \n",
    "# out_dim, n_layers, bidirectional, dropout, pad_idx):\n",
    "\n",
    "EMBEDDING_DIM = 100  # since glove has 100d\n",
    "\n",
    "args = {\n",
    "    \"vocab_size\" : len(TEXT.vocab),\n",
    "    \"embedding_dim\" : EMBEDDING_DIM,\n",
    "    \"hidden_dim\" : 256,\n",
    "    \"out_dim\" : 1,\n",
    "    \"n_layers\": 2,\n",
    "    \"bidirectional\": True,\n",
    "    \"dropout\": 0.5,\n",
    "    \"pad_idx\": PAD_IDX \n",
    "}\n",
    "\n",
    "model = Sentiment_Analyzer2(**args).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the pretrained embeds to the models embedings layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25002, 100])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeds = TEXT.vocab.vectors\n",
    "pretrained_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.1233,  0.3499,  0.6173],\n",
       "        [ 0.7262,  0.0912, -0.3891,  ...,  0.0821,  0.4440, -0.7240],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.3509, -0.8664,  1.1617,  ..., -0.5238, -1.9368,  0.2217],\n",
       "        [ 0.6168, -1.0092, -0.0051,  ..., -0.0352, -0.2554,  0.0779],\n",
       "        [ 0.4369,  0.3981, -0.2551,  ..., -0.3327,  0.4569,  0.6567]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNK and PAD value to zeros\n",
    "\n",
    "As our <unk> and <pad> token aren't in the pre-trained vocabulary they have been initialized using unk_init (an $\\mathcal{N}(0,1)$ distribution) when building our vocab. It is preferable to initialize them both to all zeros to explicitly tell our model that, initially, they are irrelevant for determining sentiment.\n",
    "    \n",
    "We do this by manually setting their row in the embedding weights matrix to zeros. We get their row by finding the index of the tokens, which we have already done for the padding index.\n",
    "\n",
    "Note: like initializing the embeddings, this should be done on the weight.data and not the weight!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.3509, -0.8664,  1.1617,  ..., -0.5238, -1.9368,  0.2217],\n",
       "        [ 0.6168, -1.0092, -0.0051,  ..., -0.0352, -0.2554,  0.0779],\n",
       "        [ 0.4369,  0.3981, -0.2551,  ..., -0.3327,  0.4569,  0.6567]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "model.embedding.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the criterion and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "lr = 0.005\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Next, we'll define our loss function. In PyTorch this is commonly called a criterion.\n",
    "\n",
    "The loss function here is binary cross entropy with logits.\n",
    "\n",
    "Our model currently outputs an unbound real number. As our labels are either 0 or 1, \n",
    "we want to restrict the predictions to a number between 0 and 1. We do this using the sigmoid or logit functions.\n",
    "\"\"\"\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# The BCEWithLogitsLoss criterion carries out both the sigmoid and the binary cross entropy steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(preds, y):\n",
    "    # preds = [batch_size]\n",
    "    # y = [batch_size, 1]\n",
    "    \n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc  = correct.sum() / len(correct)\n",
    "    \n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            reviews, text_lengths = batch.REVIEWS\n",
    "            x = review.to(device)\n",
    "            y = batch.LABEL\n",
    "            #  print(text_lengths.shape)\n",
    "            out = model(x, text_lengths)\n",
    "#           k out = model(batch.REVIEWS)\n",
    "            scores = out.squeeze(1)\n",
    "            \n",
    "            loss = criterion(scores, y.to(device))\n",
    "            acc = batch_accuracy(scores.to('cpu'),y)\n",
    "            \n",
    "            total_acc+=acc\n",
    "            total_loss+=loss.item()\n",
    "    \n",
    "    return total_loss/len(iterator), total_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May  8 09:19:32 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 165...  Off  | 00000000:57:00.0 Off |                  N/A |\n",
      "| N/A   46C    P8     4W /  N/A |    247MiB /  3911MiB |     17%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1070      G   /usr/lib/Xorg                     232MiB |\n",
      "|    0   N/A  N/A      1351      G   picom                               1MiB |\n",
      "|    0   N/A  N/A      2748      G   alacritty                           8MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]:   0%|          | 2/633 [00:04<23:58,  2.28s/it, loss=0.687, train_acc=0.531, val_acc=0, val_loss=0]"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    loop = tqdm(train_iterator,\n",
    "                total=len(train_iterator),\n",
    "                leave=True)\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    model.train()\n",
    "    for batch in loop:\n",
    "        reviews, text_lengths = batch.REVIEWS\n",
    "        x = reviews.to(device)\n",
    "        y = batch.LABEL\n",
    "#         print(text_lengths.shape)\n",
    "        out = model(x, text_lengths)\n",
    "        scores = out.squeeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(scores, y.to(device))\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_acc = batch_accuracy(scores.to('cpu'), batch.LABEL)\n",
    "#         loop.set_description(f\"Epoch [])\n",
    "        loop.set_description(f\"Epoch [{epoch + 1}/{NUM_EPOCHS}]\")\n",
    "#         loop.set_postfix(loss=loss.item(), train_acc=train_acc.item())\n",
    "#         loop.set_postfix(loss=loss.item(), train_acc=train_acc, val_loss=0, val_acc=0)\n",
    "        loop.set_postfix(loss=loss.item(), train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)\n",
    "                             \n",
    "#         break\n",
    "    \n",
    "    val_loss, val_acc  = evaluate(model, val_iterator, criterion)\n",
    "        \n",
    "    loop.set_postfix(loss=loss.item(), train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)\n",
    " \n",
    "print(\"Done training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8663424723584887\n",
      "0.5051056339707173\n"
     ]
    }
   ],
   "source": [
    "print(val_loss)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.914 | Test Acc: 49.43%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'fox', 'ca', \"n't\", 'jump', 'over', 'a', 'lazy', 'dog', '.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "tokenizer(\"The quick fox can't jump over a lazy dog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, review):\n",
    "    model.eval()\n",
    "    tokens = tokenizer(review)\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokens]\n",
    "    length = [len(indexed)]\n",
    "    \n",
    "    in_tensor = torch.LongTensor(indexed).to(device)\n",
    "    in_tensor = in_tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "\n",
    "    pred = torch.sigmoid(model(in_tensor, length_tensor))\n",
    "    return pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28592145442962646"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"An awesome movie, love it! Must watch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
