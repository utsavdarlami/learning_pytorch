{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYTORCH COMMON MISTAKES - How To Save Time ðŸ•’\n",
    "\n",
    "- https://www.youtube.com/watch?v=O2wJ3tkc-TU&list=PLhhyoLH6IjfxeoooqP9rhU3HJIAVAJ3Vz&index=14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train on a single batch to check if the model works or not\n",
    "    - x_train, y_train = next(iter(train_loader))\n",
    "\n",
    "## 2. Toggling model.train() and model.eval() while testing the model\n",
    "    - Mainly for dropout and other \n",
    "    \n",
    "## 3. Forgetting .zero_grad() in optimizer\n",
    "\n",
    "## 4. Using softmax while using CrossEntropyLoss\n",
    "    - CrossEntropyLoss uses softmax at first then log likelihood, so no point of using softmax in output layer\n",
    "## 5. Bias term with batchNorm2d  [check]\n",
    "    - bias=Flase, in conv layer\n",
    "    \n",
    "## 6. Using view as permute\n",
    "    - permute is more generalized version of transpose\n",
    "    \n",
    "## 7. Incorrect Data augmentation\n",
    "## 8. Not shuffling the Data\n",
    "    - but not for time series data\n",
    "## 9. Not Normalizing Data [check]\n",
    "    - transforms.Normalize(mean=(x,), std=(y,))\n",
    "    \n",
    "## 10. Not clipping gradients [check]\n",
    "    - mostly in RNNs, GRUs, LSTMs\n",
    "    - to solve exploting gradient\n",
    "    - after loss.backward\n",
    "        - torch.nn.utlis.clip_grad_norm(model.parameters(), max_norm=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "available_device \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/felladog/Desktop/ML/pytorch_tutorials/time_saving_in_pytorch\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# What is super in the class\n",
    "# why x is replaced \n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "# SImple example to us\n",
    "model = NN(784,10)\n",
    "x = torch.rand((128,784))\n",
    "y = model(x)\n",
    "# How did passing x to the model instance called the forward method\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(available_device)\n",
    "device = torch.device(available_device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter initialized\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "l_r = 0.001\n",
    "in_size = 784\n",
    "c_size = 10 \n",
    "\n",
    "print(\"Parameter initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded\n"
     ]
    }
   ],
   "source": [
    "train_set = datasets.MNIST(root=\"../pytorch_dataset/\",\n",
    "                           train=True,\n",
    "                           download=True,\n",
    "                           transform=transforms.ToTensor())\n",
    "test_set = datasets.MNIST(root=\"../pytorch_dataset/\",\n",
    "                          train=False,\n",
    "                          download=True,\n",
    "                          transform=transforms.ToTensor())\n",
    "\n",
    "print(\"Dataset downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "print(\"Data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized the model\n"
     ]
    }
   ],
   "source": [
    "model = NN(input_size=in_size, num_classes=c_size).to(device=device)\n",
    "print(\"initialized the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=l_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "937.5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)/ 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train on a single batch to check if the model works or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      " loss at the end of 0 epoch is 0.5224602818489075\n",
      "1\n",
      " loss at the end of 1 epoch is 0.4177483916282654\n",
      "Done Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for batch_idx, (x_train , y_train) in enumerate(train_loader):\n",
    "        # print(x_train.shape)  # torch.Size([64, 1, 28, 28])\n",
    "        # print(y_train.shape)  # torch.Size([64])\n",
    "        x_train = x_train.to(device=device)\n",
    "        y_train = y_train.to(device=device)\n",
    "        x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "        y_pred = model(x_train)\n",
    "\n",
    "        loss = criterion(y_pred, y_train) \n",
    "        # Zero previous gradients\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model). This is because by default, gradients are\n",
    "        # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "        # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    print(f\" loss at the end of {epoch} epoch is {loss}\")\n",
    "\n",
    "print(\"Done Training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 10000 images 8891 where correctly classified\n",
      "Accuracy of the model is 88.91\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        x_test, y_test = data\n",
    "        x_test = x_test.to(device=device)\n",
    "        y_test = y_test.to(device=device)\n",
    "        x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "        preds = model(x_test)\n",
    "\n",
    "        # print(preds.shape)\n",
    "        _, pred_idx = preds.max(1)\n",
    "        correct += (pred_idx == y_test).sum().item()\n",
    "        total += y_test.size(0)\n",
    "\n",
    "print(f\"Out of {total} images {correct} where correctly classified\")\n",
    "acc = (correct/total) * 100\n",
    "print(f\"Accuracy of the model is {acc:.2f}\")\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 10000 images 9371 where correctly classified\n",
      "Accuracy of the model is 93.71\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (fc1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        x_test, y_test = data\n",
    "        x_test = x_test.to(device=device)\n",
    "        y_test = y_test.to(device=device)\n",
    "        x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "        preds = model(x_test)\n",
    "\n",
    "        # print(preds.shape)\n",
    "        _, pred_idx = preds.max(1)\n",
    "        correct += (pred_idx == y_test).sum().item()\n",
    "        total += y_test.size(0)\n",
    "\n",
    "print(f\"Out of {total} images {correct} where correctly classified\")\n",
    "acc = (correct/total) * 100\n",
    "print(f\"Accuracy of the model is {acc:.2f}\")\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.max(1)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 6, 4, 9, 0, 6, 0, 4, 6, 6, 2, 6, 6, 4, 4, 4, 6, 0, 0, 1, 6, 0, 0, 0,\n",
       "        6, 6, 1, 0, 6, 4, 0, 0, 6, 0, 6, 0, 0, 0, 0, 0, 0, 6, 0, 6, 0, 0, 0, 6,\n",
       "        6, 0, 4, 1, 6, 0, 6, 6, 0, 6, 0, 6, 6, 6, 6, 6], device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = pred_idx == y_test\n",
    "print(true)\n",
    "true.sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Document about the Neural Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "name": "tutorial2.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
